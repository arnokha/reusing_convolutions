{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20->40, 40->80, 80->160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import time\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ob2torch(observation):\n",
    "    return torch.tensor(observation.copy().reshape(3, observation.shape[0], observation.shape[1])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Pong-v0\")\n",
    "observation = env.reset()\n",
    "print(observation.shape)\n",
    "observations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "n_channels = 3\n",
    "n_dim_x = observation.shape[0]\n",
    "n_dim_y = observation.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(module, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, n_out_channels_1=20, n_out_channels_2=40):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, n_out_channels_1, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(n_out_channels_1, n_out_channels_2, kernel_size=3)\n",
    "\n",
    "    def forward(self, x):    \n",
    "        model = torch.nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.conv2\n",
    "        )\n",
    "        return model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Conv2D_Chunk(nn.Module):\n",
    "    def __init__(self, n_out_channels_1=20, n_out_channels_2=40):\n",
    "        super(Conv2D_Chunk, self).__init__()\n",
    "        self.kernel_size = 3\n",
    "        self.conv1 = nn.Conv2d(3, n_out_channels_1, kernel_size=self.kernel_size) # did this to avoid padding problems when redoing indexes\n",
    "        self.part_conv1 = nn.Conv2d(3, n_out_channels_1, kernel_size=self.kernel_size) # don't overwrite forward hooks\n",
    "        self.conv2 = nn.Conv2d(n_out_channels_1, n_out_channels_2, kernel_size=self.kernel_size) # did this to avoid padding problems when redoing indexes\n",
    "        self.part_conv2 = nn.Conv2d(n_out_channels_1, n_out_channels_2, kernel_size=self.kernel_size) # don't overwrite forward hooks\n",
    "        self.activations = {}\n",
    "        self.x_prev = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## Get difference of frames\n",
    "        if self.x_prev is not None:\n",
    "            x_diff = (self.x_prev - x) #.view(1,1,n_dim_x,n_dim_y)\n",
    "            out = activation['conv2']\n",
    "        else:\n",
    "            out = self.conv2(self.conv1(x))\n",
    "            self.x_prev = x\n",
    "            return out\n",
    "            \n",
    "        ## Get indices to redo\n",
    "        redo_idx = x_diff.nonzero()\n",
    "        if redo_idx.nelement() == 0:\n",
    "            out = activation['conv2']\n",
    "            return out\n",
    "\n",
    "        min_idx_x = redo_idx.min(-2)[0][2].item()\n",
    "        min_idx_y = redo_idx.min(-2)[0][3].item()\n",
    "        max_idx_x = redo_idx.max(-2)[0][2].item()\n",
    "        max_idx_y = redo_idx.max(-2)[0][3].item()\n",
    "        #print(min_idx_x, min_idx_y, max_idx_x, max_idx_y)\n",
    "        \n",
    "        ## Fix indices on the edge since padding is not currently supported\n",
    "        if min_idx_x < self.kernel_size - 1:\n",
    "            min_idx_x = self.kernel_size - 1\n",
    "        if min_idx_y < self.kernel_size - 1:\n",
    "            min_idx_y = self.kernel_size - 1\n",
    "        if max_idx_x >= n_dim_x - (self.kernel_size - 1):\n",
    "            max_idx_x = n_dim_x - self.kernel_size\n",
    "        if max_idx_y >= n_dim_y - (self.kernel_size - 1):\n",
    "            max_idx_y = n_dim_y - self.kernel_size\n",
    "\n",
    "        #print(min_idx_x, max_idx_x, min_idx_y, max_idx_y)\n",
    "        ## Redo indices\n",
    "        r_x1 = min_idx_x - (self.kernel_size - 1)\n",
    "        r_x2 = max_idx_x + self.kernel_size\n",
    "        r_y1 = min_idx_y - (self.kernel_size - 1)\n",
    "        r_y2 = max_idx_y + self.kernel_size\n",
    "        \n",
    "        redo_area = self.part_conv2(self.part_conv1(x[:,:,r_x1:r_x2,r_y1:r_y2]))\n",
    "        \n",
    "        out[:,:,r_x1:r_x1+redo_area.shape[2],r_y1:r_y1+redo_area.shape[3]] = redo_area\n",
    "        activation['conv2'][:,:,r_x1:r_x1+redo_area.shape[2],r_y1:r_y1+redo_area.shape[3]] = redo_area\n",
    "            \n",
    "        self.x_prev = x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conv_model = Conv2D_Chunk()\n",
    "#conv_model.conv1.register_forward_hook(get_activation('conv1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y = conv_model(t.reshape(batch_size,n_channels,n_dim_x,n_dim_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Conv_Block with Conv2D for 1000 frames, with no backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv2D v.s. Chunk\n",
    " - Use the same observations to make sure results are the same\n",
    " - Lots of overhead, but still worth it if using a lot of filters (e.g. 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Pong-v0\")\n",
    "observation = env.reset()\n",
    "observations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gather observations\n",
    "n_steps=1000\n",
    "for i in range(n_steps):\n",
    "    observation,_,done,_ = env.step(np.random.choice(range(env.action_space.n)))\n",
    "    observations.append(observation.copy())\n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_out_c1 = 80 \n",
    "n_out_c2 = 160 \n",
    "n_tests = 20\n",
    "times_old = []\n",
    "times_new = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test old/standard version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3518d511cc3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mob2torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_dim_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_dim_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtimes_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arno/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-12570d2460d3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         )\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/arno/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arno/anaconda3/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arno/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arno/anaconda3/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(n_tests):\n",
    "    conv_old = Conv2D(n_out_c1, n_out_c2)\n",
    "    start = time.time()\n",
    "    for i in range(n_steps):\n",
    "        y = conv_old(ob2torch(observations[i]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))        \n",
    "    end = time.time()\n",
    "    times_old.append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = open(\"test_standard_conv_{}_{}_out.txt\".format(n_out_c1, n_out_c2), \"w\")\n",
    "text_file.write(\"Mean time: {0:.2f}\\n\".format(np.mean(times_old)))\n",
    "for i in range(n_tests):\n",
    "    text_file.write(\"Run {0:d} - time: {1:.2f}\\n\".format(i+1, times_old[i]))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f35b710b7b8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = Conv2D_Chunk(n_out_c1, n_out_c2)\n",
    "conv_model.conv2.register_forward_hook(get_activation('conv2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_tests):\n",
    "    conv_model = Conv2D_Chunk(n_out_c1, n_out_c2)\n",
    "    conv_model.conv2.register_forward_hook(get_activation('conv2'))\n",
    "    start = time.time()\n",
    "    for i in range(n_steps):\n",
    "        y = conv_model(ob2torch(observations[i]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))        \n",
    "    end = time.time()\n",
    "    times_new.append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = open(\"test_new_conv_{}_{}_out.txt\".format(n_out_c1, n_out_c2), \"w\")\n",
    "text_file.write(\"Mean time: {0:.2f}\\n\".format(np.mean(times_new)))\n",
    "for i in range(n_tests):\n",
    "    text_file.write(\"Run {0:d} - time: {1:.2f}\\n\".format(i+1, times_new[i]))\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Try backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_out_c1 = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_out_c2 = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Conv2D_Chunk(n_out_c1, n_out_c2)\n",
    "conv_model.conv2.register_forward_hook(get_activation('conv2'))\n",
    "y = conv_model(ob2torch(observations[0]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))  \n",
    "optimizer = optim.SGD(conv_model.parameters(), lr=1e-3, momentum=1e-3)\n",
    "target = torch.tensor(np.zeros((y.shape[1], y.shape[2], y.shape[3]))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(100,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "2.2929999828338623\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "n_steps=100\n",
    "seed = np.random.choice(range(100,500))\n",
    "start = time.time()\n",
    "conv_model.x_prev = None ## Necessary to reset graph, so don't have carryover between backward passes\n",
    "for i in range(n_steps):\n",
    "    print('a')\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y = conv_model(ob2torch(observations[i+seed]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))  \n",
    "    \n",
    "    loss = F.l1_loss(y.reshape((y.shape[1], y.shape[2], y.shape[3])), target)\n",
    "    \n",
    "    #if i != n_steps - 1:\n",
    "    #    loss.backward(retain_graph=True)\n",
    "    #else:\n",
    "    #    loss.backward()\n",
    "    results.append(y.detach().numpy().copy())\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test against old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model_o = Conv2D(n_out_c1, n_out_c2)\n",
    "optimizer = optim.SGD(conv_model_o.parameters(), lr=1e-3, momentum=1e-3)\n",
    "target = torch.tensor(np.zeros((y.shape[1], y.shape[2], y.shape[3]))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "6.840091705322266\n"
     ]
    }
   ],
   "source": [
    "results_o = []\n",
    "n_steps=100\n",
    "start = time.time()\n",
    "for i in range(n_steps):\n",
    "    print('a')\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y = conv_model_o(ob2torch(observations[i+seed]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))  \n",
    "    \n",
    "    loss = F.l1_loss(y.reshape((y.shape[1], y.shape[2], y.shape[3])), target)\n",
    "    \n",
    "    #loss.backward()\n",
    "    \n",
    "    results_o.append(y.detach().numpy().copy())\n",
    "    if done:\n",
    "        env.reset()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Try backprop: after 1k steps\n",
    "The computational graph of the reuse model is much larger than that of the base model, so if there is a target or reward signal that we can backpropagate on every step or every few steps, then training on the reuse model is worth it. Otherwise, it just eats up too much memory resource\n",
    " - At 10 steps, using the reuse model is much faster\n",
    " - At 100 steps, they are about the same\n",
    " - At 1000 steps, using the base model is about twice as fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model_o = Conv2D(n_out_c1, n_out_c2)\n",
    "optimizer = optim.SGD(conv_model_o.parameters(), lr=1e-3, momentum=1e-3)\n",
    "target = torch.tensor(np.zeros((y.shape[1], y.shape[2], y.shape[3]))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f9a58b870f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = Conv2D_Chunk(n_out_c1, n_out_c2)\n",
    "conv_model.conv2.register_forward_hook(get_activation('conv2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0881381034851074\n"
     ]
    }
   ],
   "source": [
    "n_steps=100\n",
    "optimizer = optim.SGD(conv_model.parameters(), lr=1e-3, momentum=1e-3)\n",
    "\n",
    "start = time.time()\n",
    "conv_model.x_prev = None ## Necessary to reset graph, so don't have carryover between backward passes\n",
    "for i in range(n_steps):\n",
    "    #print('a')\n",
    "    #optimizer.zero_grad()\n",
    "    \n",
    "    y = conv_model(ob2torch(observations[i+100]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))  \n",
    "    \n",
    "#loss = F.l1_loss(y.reshape((y.shape[1], y.shape[2], y.shape[3])), target)\n",
    "\n",
    "#loss.backward()\n",
    "\n",
    "\n",
    "#results.append(y.detach().numpy().copy())\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.17580246925354\n"
     ]
    }
   ],
   "source": [
    "conv_model = Conv2D(n_out_c1, n_out_c2)\n",
    "\n",
    "#results_o = []\n",
    "optimizer = optim.SGD(conv_model.parameters(), lr=1e-3, momentum=1e-3)\n",
    "start = time.time()\n",
    "for i in range(n_steps):\n",
    "    \n",
    "    y = conv_model(ob2torch(observations[i+100]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))  \n",
    "    \n",
    "#loss = F.l1_loss(y.reshape((y.shape[1], y.shape[2], y.shape[3])), target)\n",
    "\n",
    "#loss.backward()\n",
    "\n",
    "#results_o.append(y.detach().numpy().copy())\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use profiler\n",
    "#### Note: profiler affects timing, so if you use time.time() it will not match those found in profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f9a58b537f0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = Conv2D_Chunk(n_out_c1, n_out_c2)\n",
    "conv_model.conv2.register_forward_hook(get_activation('conv2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7746920585632324\n"
     ]
    }
   ],
   "source": [
    "n_steps=15\n",
    "optimizer = optim.SGD(conv_model.parameters(), lr=1e-3, momentum=1e-3)\n",
    "\n",
    "\n",
    "conv_model.x_prev = None ## Necessary to reset graph, so don't have carryover between backward passes\n",
    "start = time.time()\n",
    "with torch.autograd.profiler.profile() as prof:\n",
    "    for i in range(n_steps):\n",
    "        y = conv_model(ob2torch(observations[i]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))\n",
    "    #loss = F.l1_loss(y.reshape((y.shape[1], y.shape[2], y.shape[3])), target)\n",
    "    #loss.backward()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23400497436523438\n"
     ]
    }
   ],
   "source": [
    "n_steps=15\n",
    "optimizer = optim.SGD(conv_model.parameters(), lr=1e-3, momentum=1e-3)\n",
    "\n",
    "\n",
    "conv_model.x_prev = None ## Necessary to reset graph, so don't have carryover between backward passes\n",
    "start = time.time()\n",
    "\n",
    "for i in range(n_steps):\n",
    "    y = conv_model(ob2torch(observations[i+100]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))\n",
    "    #loss = F.l1_loss(y.reshape((y.shape[1], y.shape[2], y.shape[3])), target)\n",
    "    #loss.backward()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ---------------  ---------------  ---------------  ---------------  ---------------\n",
      "Name                             CPU time        CUDA time            Calls        CPU total       CUDA total\n",
      "------------------------  ---------------  ---------------  ---------------  ---------------  ---------------\n",
      "is_floating_point                 0.307us          0.000us               48         14.715us          0.000us\n",
      "expand                            1.692us          0.000us               24         40.598us          0.000us\n",
      "select                            1.060us          0.000us               48         50.884us          0.000us\n",
      "view                              2.441us          0.000us               24         58.594us          0.000us\n",
      "reshape                           3.909us          0.000us               15         58.639us          0.000us\n",
      "as_strided                        1.996us          0.000us               30         59.882us          0.000us\n",
      "tensor                            1.382us          0.000us               56         77.403us          0.000us\n",
      "slice                             1.495us          0.000us               72        107.606us          0.000us\n",
      "clone                             9.552us          0.000us               12        114.624us          0.000us\n",
      "max                               5.239us          0.000us               24        125.737us          0.000us\n",
      "min                               6.526us          0.000us               24        156.629us          0.000us\n",
      "th_sub                           20.275us          0.000us               14        283.852us          0.000us\n",
      "sub                              21.512us          0.000us               14        301.165us          0.000us\n",
      "_cast_Float                      85.163us          0.000us               15       1277.449us          0.000us\n",
      "nonzero                         112.159us          0.000us               14       1570.233us          0.000us\n",
      "thnn_conv2d_forward            1546.162us          0.000us               26      40200.207us          0.000us\n",
      "thnn_conv2d                    1547.101us          0.000us               26      40224.627us          0.000us\n",
      "_convolution_nogroup           1548.360us          0.000us               26      40257.360us          0.000us\n",
      "_convolution                   1556.525us          0.000us               26      40469.650us          0.000us\n",
      "convolution                    1557.423us          0.000us               26      40493.004us          0.000us\n",
      "conv2d                         1558.267us          0.000us               26      40514.938us          0.000us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3894834518432617\n"
     ]
    }
   ],
   "source": [
    "conv_model = Conv2D(n_out_c1, n_out_c2)\n",
    "optimizer = optim.SGD(conv_model.parameters(), lr=1e-3, momentum=1e-3)\n",
    "\n",
    "start = time.time()\n",
    "#with torch.autograd.profiler.profile() as prof:\n",
    "for i in range(n_steps):\n",
    "    y = conv_model(ob2torch(observations[i+100]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))\n",
    "    #loss = F.l1_loss(y.reshape((y.shape[1], y.shape[2], y.shape[3])), target)\n",
    "    #loss.backward()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ---------------  ---------------  ---------------  ---------------  ---------------\n",
      "Name                             CPU time        CUDA time            Calls        CPU total       CUDA total\n",
      "------------------------  ---------------  ---------------  ---------------  ---------------  ---------------\n",
      "reshape                           7.099us          0.000us               15        106.488us          0.000us\n",
      "as_strided                        3.674us          0.000us               30        110.207us          0.000us\n",
      "tensor                            1.974us          0.000us               60        118.458us          0.000us\n",
      "_cast_Float                      92.760us          0.000us               15       1391.398us          0.000us\n",
      "thnn_conv2d_forward           13127.880us          0.000us               30     393836.386us          0.000us\n",
      "thnn_conv2d                   13129.270us          0.000us               30     393878.114us          0.000us\n",
      "_convolution_nogroup          13131.118us          0.000us               30     393933.535us          0.000us\n",
      "_convolution                  13138.838us          0.000us               30     394165.129us          0.000us\n",
      "convolution                   13140.357us          0.000us               30     394210.716us          0.000us\n",
      "conv2d                        13141.488us          0.000us               30     394244.648us          0.000us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f792a4de2b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = Conv2D_Chunk(60)\n",
    "#conv_model.conv1.load_state_dict(conv_old.conv1.state_dict())\n",
    "#conv_model.part_conv.load_state_dict(conv_old.conv1.state_dict())\n",
    "conv_model.conv1.register_forward_hook(get_activation('conv1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6274147033691406\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "start = time.time()\n",
    "for i in range(n_steps):\n",
    "    y = conv_model(ob2torch(observations[i]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))    \n",
    "    #results.append(y.detach().numpy().copy())\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-b71debdc11ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_o\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "for i in range(n_steps):\n",
    "    if not np.allclose(results_o[i].detach().numpy(), results[i], atol=1e-4):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with different number of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gather observations\n",
    "n_steps=1000\n",
    "for i in range(n_steps):\n",
    "    observation,_,done,_ = env.step(np.random.choice(range(env.action_space.n)))\n",
    "    observations.append(observation.copy())\n",
    "    if done:\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_tests_per_setting = 5\n",
    "out_channels_to_test = [20, 50, 100, 200]\n",
    "times_old = {}\n",
    "times_new = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Number of output channels: 20\n",
      "----------------------------------------\n",
      "Mean time to completion using old method was: 1.24\n",
      "Median time to completion using old method was: 1.24\n",
      "Standard deviation time to completion using old method was: 0.01\n",
      "\n",
      "Mean time to completion using old method was: 1.12\n",
      "Median time to completion using old method was: 1.12\n",
      "Standard deviation time to completion using old method was: 0.00\n",
      "----------------------------------------\n",
      "Number of output channels: 50\n",
      "----------------------------------------\n",
      "Mean time to completion using old method was: 2.41\n",
      "Median time to completion using old method was: 2.28\n",
      "Standard deviation time to completion using old method was: 0.17\n",
      "\n",
      "Mean time to completion using old method was: 2.25\n",
      "Median time to completion using old method was: 1.99\n",
      "Standard deviation time to completion using old method was: 0.38\n",
      "----------------------------------------\n",
      "Number of output channels: 100\n",
      "----------------------------------------\n",
      "Mean time to completion using old method was: 4.03\n",
      "Median time to completion using old method was: 3.76\n",
      "Standard deviation time to completion using old method was: 0.35\n",
      "\n",
      "Mean time to completion using old method was: 4.08\n",
      "Median time to completion using old method was: 3.65\n",
      "Standard deviation time to completion using old method was: 0.65\n",
      "----------------------------------------\n",
      "Number of output channels: 200\n",
      "----------------------------------------\n",
      "Mean time to completion using old method was: 49.95\n",
      "Median time to completion using old method was: 34.51\n",
      "Standard deviation time to completion using old method was: 30.08\n",
      "\n",
      "Mean time to completion using old method was: 147.24\n",
      "Median time to completion using old method was: 159.93\n",
      "Standard deviation time to completion using old method was: 36.60\n"
     ]
    }
   ],
   "source": [
    "for oc in out_channels_to_test:\n",
    "    times_old[oc] = []\n",
    "    times_new[oc] = []\n",
    "    for i in range(n_tests_per_setting):\n",
    "        ## Time old\n",
    "        conv_old = Conv2D(oc)\n",
    "        \n",
    "        results_o = []\n",
    "\n",
    "        start = time.time()\n",
    "        for i in range(n_steps):\n",
    "            y = conv_old(ob2torch(observations[i]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))    \n",
    "            results_o.append(y)\n",
    "        end = time.time()\n",
    "        times_old[oc].append(end - start)\n",
    "        \n",
    "        ## Time new\n",
    "        conv_model = Conv2D_Chunk(oc)\n",
    "        conv_model.conv1.load_state_dict(conv_old.conv1.state_dict())\n",
    "        conv_model.part_conv.load_state_dict(conv_old.conv1.state_dict())\n",
    "        conv_model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        start = time.time()\n",
    "        for i in range(n_steps):\n",
    "            y = conv_model(ob2torch(observations[i]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))    \n",
    "            results.append(y.detach().numpy().copy())\n",
    "        end = time.time()\n",
    "        times_new[oc].append(end - start)\n",
    "        \n",
    "        ## Confirm results are the same\n",
    "        for i in range(n_steps):\n",
    "            if not np.allclose(results_o[i].detach().numpy(), results[i], atol=1e-4):\n",
    "                print(i)\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"Number of output channels: {}\".format(oc))\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"Mean time to completion using old method was: {0:.2f}\".format(np.mean(times_old[oc])))\n",
    "    print(\"Median time to completion using old method was: {0:.2f}\".format(np.median(times_old[oc])))\n",
    "    print(\"Standard deviation time to completion using old method was: {0:.2f}\".format(np.std(times_old[oc])))\n",
    "    print()\n",
    "    print(\"Mean time to completion using new method was: {0:.2f}\".format(np.mean(times_new[oc])))\n",
    "    print(\"Median time to completion using new method was: {0:.2f}\".format(np.median(times_new[oc])))\n",
    "    print(\"Standard deviation time to completion using new method was: {0:.2f}\".format(np.std(times_new[oc])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for oc in out_channels_to_test:\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"Number of output channels: {}\".format(oc))\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"Mean time to completion using old method was: {0:.2f}\".format(np.mean(times_old[oc])))\n",
    "    print(\"Median time to completion using old method was: {0:.2f}\".format(np.median(times_old[oc])))\n",
    "    print(\"Standard deviation time to completion using old method was: {0:.2f}\".format(np.std(times_old[oc])))\n",
    "    print()\n",
    "    print(\"Mean time to completion using old method was: {0:.2f}\".format(np.mean(times_new[oc])))\n",
    "    print(\"Median time to completion using old method was: {0:.2f}\".format(np.median(times_new[oc])))\n",
    "    print(\"Standard deviation time to completion using old method was: {0:.2f}\".std(np.mean(times_new[oc])))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try backprop? Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = torch.tensor(np.zeros((results[0].shape[1], results[0].shape[2], results[0].shape[3]))).float()\n",
    "optimizer = optim.SGD(conv_old.parameters(), lr=1e-3, momentum=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5996429920196533\n"
     ]
    }
   ],
   "source": [
    "results_o = []\n",
    "n_steps=100\n",
    "start = time.time()\n",
    "for i in range(n_steps):\n",
    "     \n",
    "    optimizer.zero_grad()\n",
    "    observation,_,done,_ = env.step(np.random.choice(range(env.action_space.n)))\n",
    "    t = ob2torch(observation)\n",
    "    y = conv_old(t.reshape(batch_size,n_channels,n_dim_x,n_dim_y))   \n",
    "    \n",
    "    loss = F.l1_loss(y.reshape((y.shape[1], y.shape[2], y.shape[3])), target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    results_o.append(y)\n",
    "    observations.append(observation.copy())\n",
    "    \n",
    "    if done:\n",
    "        env.reset()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try backprop? New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(conv_model.parameters(), lr=1e-3, momentum=1e-3)\n",
    "target = torch.tensor(np.zeros((y.shape[1], y.shape[2], y.shape[3]))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "0.09183168411254883\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "n_steps=10\n",
    "start = time.time()\n",
    "for i in range(n_steps):\n",
    "    print('a')\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y = conv_model(ob2torch(observations[i]).reshape(batch_size,n_channels,n_dim_x,n_dim_y))  \n",
    "    \n",
    "    loss = F.l1_loss(y.reshape((y.shape[1], y.shape[2], y.shape[3])), target)\n",
    "    #loss.backward(retain_graph=True)\n",
    "    if i != n_steps - 1:\n",
    "        loss.backward(retain_graph=True)\n",
    "    else:\n",
    "        loss.backward()\n",
    "    results.append(y.detach().numpy().copy())\n",
    "    if done:\n",
    "        env.reset()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "conv_model.x_prev = None ## Necessary to reset graph, so don't have carryover between backward passes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with different number of filters - BACKPROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_tests_per_setting = 20\n",
    "out_channels_to_test = [20, 50, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
